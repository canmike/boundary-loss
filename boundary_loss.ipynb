{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. dist_map_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, BinaryIO, Match, Pattern, Tuple, Union, Optional, cast\n",
    "from typing import Any, Callable, Iterable, List, Set, Tuple, TypeVar, Union, cast\n",
    "from functools import partial\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from operator import itemgetter, mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def uniq(a: Tensor) -> Set:\n",
    "    return set(torch.unique(a.cpu()).numpy())\n",
    "\n",
    "def sset(a: Tensor, sub) -> bool:\n",
    "    return uniq(a).issubset(sub)\n",
    "\n",
    "def simplex(t: Tensor, axis=1) -> bool:\n",
    "    _sum = cast(Tensor, t.sum(axis).type(torch.float32))\n",
    "    _ones = torch.ones_like(_sum, dtype=torch.float32)\n",
    "    return torch.allclose(_sum, _ones)\n",
    "\n",
    "def one_hot(t: Tensor, axis=1) -> bool:\n",
    "    return simplex(t, axis) and sset(t, [0, 1])\n",
    "\n",
    "def class2one_hot(seg: Tensor, K: int) -> Tensor:\n",
    "    # Breaking change but otherwise can't deal with both 2d and 3d\n",
    "    # if len(seg.shape) == 3:  # Only w, h, d, used by the dataloader\n",
    "    #     return class2one_hot(seg.unsqueeze(dim=0), K)[0]\n",
    "\n",
    "    assert sset(seg, list(range(K))), (uniq(seg), K)\n",
    "\n",
    "    b, *img_shape = seg.shape  # type: Tuple[int, ...]\n",
    "\n",
    "    device = seg.device\n",
    "    res = torch.zeros((b, K, *img_shape), dtype=torch.int32, device=device).scatter_(1, seg[:, None, ...], 1)\n",
    "\n",
    "    assert res.shape == (b, K, *img_shape)\n",
    "    assert one_hot(res)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt_transform(resolution: Tuple[float, ...], K: int):\n",
    "        return transforms.Compose([\n",
    "                lambda img: np.array(img)[...],\n",
    "                lambda nd: torch.tensor(nd, dtype=torch.int64)[None, ...],  # Add one dimension to simulate batch\n",
    "                partial(class2one_hot, K=K),\n",
    "                itemgetter(0)  # Then pop the element to go back to img shape\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import distance_transform_edt as eucl_distance\n",
    "\n",
    "def one_hot2dist(seg: np.ndarray, resolution: Tuple[float, float, float] = None,\n",
    "                 dtype=None) -> np.ndarray:\n",
    "    assert one_hot(torch.tensor(seg), axis=0)\n",
    "    K: int = len(seg)\n",
    "\n",
    "    res = np.zeros_like(seg, dtype=dtype)\n",
    "    for k in range(K):\n",
    "        posmask = seg[k].astype(bool)\n",
    "\n",
    "        if posmask.any():\n",
    "            negmask = ~posmask\n",
    "            res[k] = eucl_distance(negmask, sampling=resolution) * negmask \\\n",
    "                - (eucl_distance(posmask, sampling=resolution) - 1) * posmask\n",
    "        # The idea is to leave blank the negative classes\n",
    "        # since this is one-hot encoded, another class will supervise that pixel\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_map_transform(resolution: Tuple[float, ...], K: int):\n",
    "        return transforms.Compose([\n",
    "                gt_transform(resolution, K),\n",
    "                lambda t: t.cpu().numpy(),\n",
    "                partial(one_hot2dist, resolution=resolution),\n",
    "                lambda nd: torch.tensor(nd, dtype=torch.float32)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 3, 256, 256]), torch.Size([8, 256, 256]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 2\n",
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "\n",
    "images = torch.randint(0, 1, (BATCH_SIZE, NUM_CHANNELS, HEIGHT, WIDTH), dtype=torch.float32)\n",
    "labels = torch.randint(0, NUM_CLASSES, (BATCH_SIZE, HEIGHT, WIDTH), dtype=torch.int64)\n",
    "\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 256, 256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_labels = torch.stack([class2one_hot(label.unsqueeze(0), NUM_CLASSES).squeeze(0) for label in labels])\n",
    "\n",
    "one_hot_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "disttransform = dist_map_transform([1, 1], NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 256, 256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_map_labels: Tensor = torch.stack([disttransform(label) for label in labels])\n",
    "\n",
    "dist_map_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GeneralizedDiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor, einsum\n",
    "\n",
    "class GeneralizedDiceLoss():\n",
    "    def __init__(self, **kwargs):\n",
    "        # Self.idc is used to filter out some classes of the target mask. Use fancy indexing\n",
    "        self.idc: List[int] = kwargs[\"idc\"]\n",
    "        print(f\"Initialized {self.__class__.__name__} with {kwargs}\")\n",
    "\n",
    "    def __call__(self, probs: Tensor, target: Tensor) -> Tensor:\n",
    "        assert simplex(probs) and simplex(target)\n",
    "\n",
    "        pc = probs[:, self.idc, ...].type(torch.float32)\n",
    "        tc = target[:, self.idc, ...].type(torch.float32)\n",
    "\n",
    "        w: Tensor = 1 / ((einsum(\"bkwh->bk\", tc).type(torch.float32) + 1e-10) ** 2)\n",
    "        intersection: Tensor = w * einsum(\"bkwh,bkwh->bk\", pc, tc)\n",
    "        union: Tensor = w * (einsum(\"bkwh->bk\", pc) + einsum(\"bkwh->bk\", tc))\n",
    "\n",
    "        divided: Tensor = 1 - 2 * (einsum(\"bk->b\", intersection) + 1e-10) / (einsum(\"bk->b\", union) + 1e-10)\n",
    "\n",
    "        loss = divided.mean()\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. BoundaryLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurfaceLoss():\n",
    "    def __init__(self, **kwargs):\n",
    "        # Self.idc is used to filter out some classes of the target mask. Use fancy indexing\n",
    "        self.idc: List[int] = kwargs[\"idc\"]\n",
    "        print(f\"Initialized {self.__class__.__name__} with {kwargs}\")\n",
    "\n",
    "    def __call__(self, probs: Tensor, dist_maps: Tensor) -> Tensor:\n",
    "        assert simplex(probs)\n",
    "        assert not one_hot(dist_maps)\n",
    "\n",
    "        pc = probs[:, self.idc, ...].type(torch.float32)\n",
    "        dc = dist_maps[:, self.idc, ...].type(torch.float32)\n",
    "\n",
    "        multipled = einsum(\"bkwh,bkwh->bkwh\", pc, dc)\n",
    "\n",
    "        loss = multipled.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "BoundaryLoss = SurfaceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized GeneralizedDiceLoss with {'idc': [0, 1]}\n",
      "Initialized SurfaceLoss with {'idc': [1]}\n"
     ]
    }
   ],
   "source": [
    "dice_loss = GeneralizedDiceLoss(idc=[0, 1])\n",
    "boundary_loss = BoundaryLoss(idc=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 3, 256, 256]),\n",
       " torch.Size([8, 256, 256]),\n",
       " torch.Size([8, 2, 256, 256]),\n",
       " torch.Size([8, 2, 256, 256]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, labels.shape, one_hot_labels.shape, dist_map_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 2, 256, 256]), torch.Size([8, 2, 256, 256]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "pred_logits = torch.rand(BATCH_SIZE, NUM_CLASSES, HEIGHT, WIDTH)\n",
    "pred_probs = F.softmax(pred_logits, dim=1)\n",
    "pred_logits.shape, pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 2, 256, 256]), torch.Size([8, 2, 256, 256]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs.shape, one_hot_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 0.502377\n",
      "Dice loss: 0.499884\n",
      "Boundary loss: 0.249297\n"
     ]
    }
   ],
   "source": [
    "a = 0.01\n",
    "\n",
    "gdl_loss = dice_loss(pred_probs, one_hot_labels)\n",
    "bl_loss = boundary_loss(pred_probs, dist_map_labels)\n",
    "\n",
    "total_loss = gdl_loss + a * bl_loss\n",
    "print(f\"Total loss: {total_loss:.6f}\")\n",
    "print(f\"Dice loss: {gdl_loss:.6f}\")\n",
    "print(f\"Boundary loss: {bl_loss:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
